<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5: Image Feature Detection and Automatic Stitching</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-top: 30px;
            text-align: center;
        }
        h2 {
            color: #34495e;
            margin-top: 40px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        h3 {
            color: #555;
            margin-top: 25px;
        }
        .section {
            background: white;
            padding: 30px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .image-container {
            text-align: center;
            margin: 30px 0;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .image-caption {
            font-style: italic;
            color: #666;
            margin-top: 10px;
            font-size: 0.95em;
            text-align: center;
        }
        .comparison {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
            gap: 20px;
            margin: 30px 0;
        }
        .comparison-item {
            flex: 1;
            min-width: 300px;
            text-align: center;
        }
        .comparison-item img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .grayscale-img {
            filter: grayscale(100%);
        }
        .mosaic-img {
            max-width: 50% !important;
        }
        .code-block {
            background-color: #f8f8f8;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 15px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            white-space: pre-wrap;
        }
        .explanation {
            background-color: #e8f4f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        .highlight {
            background-color: #fff3cd;
            padding: 15px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
            border-radius: 4px;
        }
        .key-result {
            background-color: #d4edda;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        p {
            text-align: justify;
            color: #444;
        }
        ul {
            padding-left: 20px;
        }
        li {
            margin-bottom: 8px;
        }
        .mosaic-grid {
            display: grid;
            grid-template-columns: 1fr;
            gap: 30px;
            margin: 30px 0;
        }
        @media (max-width: 600px) {
            .comparison {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <h1>Project 5: Image Feature Detection and Automatic Stitching</h1>
    
    <div class="section">
        <h2>Overview</h2>
        <p>
            This project implements a complete feature detection and image stitching pipeline. The system automatically detects Harris corners in images, extracts normalized feature descriptors, matches features between image pairs, and creates seamless mosaics using 4-point RANSAC for automatic homography estimation. This demonstrates the complete workflow for creating panoramic images from multiple overlapping views.
        </p>
        <div class="key-result">
            <strong>Key Achievement:</strong> Implemented fully automatic image stitching without requiring manual correspondence selection. The RANSAC algorithm robustly estimates homography transformations from noisy feature matches, enabling the creation of high-quality panoramic mosaics from multiple perspectives.
        </div>
    </div>

    <div class="section">
        <h2>Part 1: Harris Corner Detection</h2>
        
        <h3>Overview of Harris Detector</h3>
        <p>
            The Harris corner detector identifies interest points in images that are stable and distinctive. It computes the Harris response (H) for each pixel based on the structure tensor, which captures how pixel intensity changes in different directions. Corners are pixels where intensity changes significantly in multiple directions.
        </p>
        <div class="explanation">
            <strong>Why Harris Corners?</strong> Harris corners are rotation-invariant and have good repeatability across different views of the same scene. This makes them ideal for feature matching and image alignment tasks. The detector is relatively fast and reliable compared to more complex methods.
        </div>

        <h3>Raw Harris Corner Detection</h3>
        <p>
            We begin by detecting Harris corners in both the left and right perspective images. The initial detection typically finds a large number of corners (1350+ in our example).
        </p>
        
        <div class="image-container">
            <img src="final_images/03_harris_corners_all.png" alt="Harris Corners Detection">
            <p class="image-caption">
                <strong>Figure 1:</strong> Harris corner detection on left and right car images showing all detected corners marked in red.
                Left: 1350 corners | Right: 1436 corners
            </p>
        </div>

        <h3>Adaptive Non-Maximum Suppression (ANMS)</h3>
        <p>
            While Harris corners are numerous, many are clustered in textured regions. ANMS (Adaptive Non-Maximum Suppression) selects the strongest corners while ensuring they are spatially distributed. The algorithm keeps a corner only if it has a larger Harris response than all stronger corners within a certain radius.
        </p>
        
        <div class="code-block">
Algorithm: ANMS
1. Sort corners by Harris strength (descending)
2. For each corner, compute radius to nearest stronger corner
3. Keep top N corners with largest radii
4. Result: Well-distributed, distinctive corners</div>

        <p>
            By selecting the top 50 corners with ANMS, we significantly reduce noise and focus on the most distinctive features.
        </p>

        <div class="image-container">
            <img src="final_images/04_anms_corners.png" alt="ANMS Corners">
            <p class="image-caption">
                <strong>Figure 2:</strong> ANMS-selected corners showing 50 most distinctive and well-distributed corners on each image. These corners are more reliable for feature matching.
            </p>
        </div>

        <div class="key-result">
            <strong>Impact:</strong> ANMS reduces the corner count from 1350+ to 50, focusing on the most distinctive features while maintaining spatial distribution. This leads to more stable and efficient feature matching.
        </div>
    </div>

    <div class="section">
        <h2>Part 2: Feature Descriptor Extraction</h2>
        
        <h3>8x8 Normalized Patch Descriptors</h3>
        <p>
            For each corner detected by ANMS, we extract a local 40×40 patch centered at the corner. This patch is:
        </p>
        <ul>
            <li>Resized to 8×8 pixels using anti-aliasing interpolation</li>
            <li>Normalized to have zero mean (subtract mean)</li>
            <li>Normalized to have unit variance (divide by standard deviation)</li>
            <li>Flattened into a 64-dimensional feature vector</li>
        </ul>

        <p>
            This normalization is crucial as it makes descriptors invariant to illumination changes and scale variations, allowing robust matching across different viewing conditions.
        </p>

        <div class="explanation">
            <strong>Why Normalization?</strong> Zero-meaning removes the average brightness of the patch, making it invariant to global illumination changes. Unit variance normalization compensates for local contrast differences. Together, these ensure that the same physical feature produces similar descriptors across different images.
        </div>

        <h3>Extracted Features - Left Image</h3>
        <p>
            Here we visualize 5 example 8×8 feature descriptors extracted from corners in the left image, along with their locations on the image.
        </p>

        <div class="image-container">
            <img src="final_images/05_left_car_8x8_features.png" alt="Left Image Features">
            <p class="image-caption">
                <strong>Figure 3:</strong> Left image showing 5 extracted 8×8 normalized feature descriptors (left panel) and their corner locations on the image (right panel). The numbered red dots indicate where each feature was extracted.
            </p>
        </div>

        <h3>Extracted Features - Right Image</h3>
        <p>
            Similarly, we extract features from the right image showing the corresponding distinctive regions.
        </p>

        <div class="image-container">
            <img src="final_images/06_right_car_8x8_features.png" alt="Right Image Features">
            <p class="image-caption">
                <strong>Figure 4:</strong> Right image showing 5 extracted 8×8 normalized feature descriptors and their locations. 
            </p>
        </div>

        <div class="key-result">
            <strong>Feature Properties:</strong> Each 8×8 descriptor captures local appearance around a corner. The normalization ensures that similar regions appear nearly identical in the 64-dimensional feature space, even under different lighting and viewing angles.
        </div>
    </div>

    <div class="section">
        <h2>Part 3: Feature Matching</h2>
        
        <h3>Matching Strategy: Lowe's Ratio Test</h3>
        <p>
            To match features between images, we use Lowe's ratio test, which compares the distance to the nearest neighbor with the distance to the second-nearest neighbor. This test rejects ambiguous matches where multiple database features are similarly close to a query feature.
        </p>

        <div class="code-block">
Lowe's Ratio Test:
For each feature in image 1:
  - Find distance to nearest feature in image 2 (d1)
  - Find distance to second-nearest feature in image 2 (d2)
  - If d1/d2 < threshold (0.40-0.80), accept match
  - Otherwise, reject as ambiguous</div>

        <p>
            A threshold of 0.60 means we only accept matches where the nearest neighbor is significantly closer than the second-nearest, indicating a confident match.
        </p>

        <h3>Feature Matching Results</h3>
        <p>
            Using Lowe's ratio test with threshold 0.60, we find matches between features across the two images.
        </p>

        <div class="image-container">
            <img src="final_images/07_feature_matches.png" alt="Feature Matches">
            <p class="image-caption">
                <strong>Figure 5:</strong> Feature matching results showing identified correspondences between images. Red circles on the left image and blue circles on the right image show matched feature locations, with matching pairs labeled with the same number.
            </p>
        </div>
    </div>

    <div class="section">
        <h2>Part 4: 4-Point RANSAC for Automatic Image Stitching</h2>
        
        <h3>RANSAC Overview</h3>
        <p>
            RANSAC (Random Sample Consensus) is a robust algorithm for estimating model parameters from data containing outliers. While feature matching produces many correct correspondences, some matches are still incorrect (outliers). RANSAC iteratively:
        </p>
        <ol>
            <li>Randomly selects 4 point correspondences</li>
            <li>Computes a homography matrix H from these 4 points</li>
            <li>Tests how many other point pairs satisfy this homography (inliers)</li>
            <li>Keeps the homography with the maximum number of inliers</li>
        </ol>

        <h3>Implementation Details</h3>
        <div class="code-block">
RANSAC Parameters:
- Homography Threshold: 0.4-0.8
- Number of Corners: 50-500
- Inlier threshold: 5-10 pixels (depending on image pair)
- Match sample size: 4 points

Inlier Check:
For each point pair (p1, p2):
  - Warp p1 using H
  - Distance = ||H @ p1 - p2||
  - If distance < Homography Threshold: inlier</div>

        <h3>Results: Automatic Stitching Comparison</h3>
        
        <h4>Mosaic 1: Perspective Car Images</h4>
        <p><strong>Input Images:</strong></p>
        <div class="comparison">
            <div class="comparison-item">
                <img src="../4/images/left_perspective.jpg" alt="Left Car Image" class="grayscale-img">
                <p class="image-caption">Left perspective view</p>
            </div>
            <div class="comparison-item">
                <img src="../4/images/right_perspective.jpg" alt="Right Car Image" class="grayscale-img">
                <p class="image-caption">Right perspective view</p>
            </div>
        </div>
        <p><strong>Automatic Stitching Result:</strong></p>
        <div class="image-container">
            <img src="final_images/08_car_mosaic_ransac.png" alt="Car Mosaic RANSAC" class="mosaic-img">
            <p class="image-caption">
                <strong>Figure 6:</strong> Automatically stitched car mosaic using 4-point RANSAC. The algorithm found 101 inliers out of 140 feature matches (72.1% inlier quality), resulting in good 
                alignment between the two perspectives. The wide field-of-view panorama shows both the front and side of the vehicle.
            </p>
        </div>

        <div class="key-result">
            <strong>Car Mosaic Quality:</strong> RANSAC found 101 inliers (72.1% match quality), indicating reliable feature correspondences. The resulting mosaic is sharp and well-aligned with no visible seams.
        </div>

        <h4>Mosaic 2: Room Interior</h4>
        <p><strong>Input Images:</strong></p>
        <div class="comparison">
            <div class="comparison-item">
                <img src="images/left_pic_room.jpg" alt="Left Room Image" class="grayscale-img">
                <p class="image-caption">Left room view</p>
            </div>
            <div class="comparison-item">
                <img src="images/right_pic_room.jpg" alt="Right Room Image" class="grayscale-img">
                <p class="image-caption">Right room view</p>
            </div>
        </div>

        <p><strong>Automatic Stitching Result:</strong></p>
        <div class="image-container">
            <img src="final_images/09_room_mosaic_ransac.png" alt="Room Mosaic RANSAC" class="mosaic-img">
            <p class="image-caption">
                <strong>Figure 7:</strong> Room interior mosaic created automatically from two overlapping views. RANSAC identified 87 inliers from 187 feature matches (46.5% inlier quality), 
                showing good performance even with moderate outlier contamination.
            </p>
        </div>

        <div class="key-result">
            <strong>Room Mosaic Quality:</strong> Despite containing more texture variation and potential ambiguous matches, RANSAC successfully estimated the transformation. The 87 inliers provide sufficient constraint for accurate stitching.
        </div>

        <h4>Mosaic 3: Same Person Pointing</h4>
        <p><strong>Input Images:</strong></p>
        <div class="comparison">
            <div class="comparison-item">
                <img src="images/left_image_fih.jpg" alt="Left Sign Image" class="grayscale-img">
                <p class="image-caption">Left sign view</p>
            </div>
            <div class="comparison-item">
                <img src="images/right_image_fih.jpg" alt="Right Sign Image" class="grayscale-img">
                <p class="image-caption">Right sign view</p>
            </div>
        </div>
        <p><strong>Automatic Stitching Result:</strong></p>
        <div class="image-container">
            <img src="final_images/10_sign_mosaic_ransac.png" alt="Sign Mosaic RANSAC" class="mosaic-img">
            <p class="image-caption">
                <strong>Figure 8:</strong> Sign mosaic showing high-frequency structured content. RANSAC found 34 inliers from 52 matches (65.4% inlier quality).
                This mosaic isn't as good due to a large change in perspective between the two images. Center of the image is more distorted than the edges.
            </p>
        </div>

        <h4>Mosaic 4: House Exterior</h4>
        <p><strong>Input Images:</strong></p>
        <div class="comparison">
            <div class="comparison-item">
                <img src="images/left_house.jpg" alt="Left House Image" class="grayscale-img">
                <p class="image-caption">Left house view</p>
            </div>
            <div class="comparison-item">
                <img src="images/right_house.jpg" alt="Right House Image" class="grayscale-img">
                <p class="image-caption">Right house view</p>
            </div>
        </div>

        <p><strong>Automatic Stitching Result:</strong></p>
        <div class="image-container">
            <img src="final_images/11_house_mosaic_ransac.png" alt="House Mosaic RANSAC" class="mosaic-img">
            <p class="image-caption">
                <strong>Figure 9:</strong> House exterior panorama demonstrating RANSAC's ability to handle scenes with depth. The algorithm found 86 inliers from 106 matches (81.1% inlier quality), indicating excellent feature correspondence quality on structured outdoor scenes.
            </p>
        </div>

        <div class="key-result">
            <strong>House Mosaic Quality:</strong> RANSAC achieved 81.1% inlier ratio, the second highest among all tests. The well-structured facade with many distinctive features enables good automatic stitching.
        </div>

        <h3>RANSAC Performance Summary</h3>
        <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
            <tr style="background-color: #3498db; color: white;">
                <th style="border: 1px solid #ddd; padding: 10px;">Scene</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Matches</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Inliers</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Inlier %</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Quality</th>
            </tr>
            <tr>
                <td style="border: 1px solid #ddd; padding: 10px;">Car (Perspective)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">140</td>
                <td style="border: 1px solid #ddd; padding: 10px;">101</td>
                <td style="border: 1px solid #ddd; padding: 10px;">72.1%</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Good</td>
            </tr>
            <tr style="background-color: #f0f0f0;">
                <td style="border: 1px solid #ddd; padding: 10px;">Room (Interior)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">187</td>
                <td style="border: 1px solid #ddd; padding: 10px;">87</td>
                <td style="border: 1px solid #ddd; padding: 10px;">46.5%</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Good</td>
            </tr>
            <tr>
                <td style="border: 1px solid #ddd; padding: 10px;">Sign (Text)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">52</td>
                <td style="border: 1px solid #ddd; padding: 10px;">34</td>
                <td style="border: 1px solid #ddd; padding: 10px;">65.4%</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Distorted in center</td>
            </tr>
            <tr style="background-color: #f0f0f0;">
                <td style="border: 1px solid #ddd; padding: 10px;">House (Exterior)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">106</td>
                <td style="border: 1px solid #ddd; padding: 10px;">86</td>
                <td style="border: 1px solid #ddd; padding: 10px;">81.1%</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Good</td>
            </tr>
        </table>
    </div>